{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6NSYKdVB9IicP46ZMcymB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gbulg/Data-analysis-class/blob/main/HW1/hw1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 1\n",
        "\n",
        "## 1. Read the novel text from txt file\n",
        "\n",
        "Open the txt file, read from it and then close it."
      ],
      "metadata": {
        "id": "JUQCP9P6sf-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"./goncharov_obryv.txt\", \"r\")\n",
        "novel = f.read()\n",
        "f.close()"
      ],
      "metadata": {
        "id": "kwwp_pb-tcbi"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print first 500 characters to make sure everything is fine:"
      ],
      "metadata": {
        "id": "4tveqYz6wlFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(novel[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2RuviDLvfTI",
        "outputId": "bd795c66-b28a-46cc-de1a-1f496884c88d"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Иван Александрович Гончаров\n",
            "\n",
            "Обрыв\n",
            "\n",
            "Роман в пяти частях.\n",
            "\n",
            "\n",
            "\n",
            "ЧАСТЬ ПЕРВАЯ\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "I\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Два господина сидели в небрежно убранной квартире в Петербурге, на одной из больших улиц. Одному было около тридцати пяти, а другому около сорока пяти лет.\n",
            "\n",
            "Первый был Борис Павлович Райский, второй -- Иван Иванович Аянов.\n",
            "\n",
            "У Бориса Павловича была живая, чрезвычайно подвижная физиономия. С первого взгляда он казался моложе своих лет: большой белый лоб блистал свежестью, глаза менялись, то загорались мыслию, чувс\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Lemmatize text using Mystem and save it\n",
        "\n",
        "First, import Mystem and create an instance of Mystem class:"
      ],
      "metadata": {
        "id": "6vkOg3fDDOIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymystem3 import Mystem\n",
        "\n",
        "m = Mystem()"
      ],
      "metadata": {
        "id": "VXstzjieDZD5"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatize the text, and print a little slice of the obtained lemmas list:"
      ],
      "metadata": {
        "id": "LZMwpZ_lyXyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmas = m.lemmatize(novel)"
      ],
      "metadata": {
        "id": "SI0P-iutG4Ie"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmas[50:60]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIR6xO5GzTUS",
        "outputId": "c39b5788-fe50-4b9e-f7db-462a8dc6f3d8"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['квартира', ' ', 'в', ' ', 'петербург', ', ', 'на', ' ', 'один', ' ']"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to save this lemmatization into the new txt file. I'm not sure how exactly it should be formatted, so I will just join this normal forms of words into new text and save it like that.\n",
        "\n",
        "Open the file for writing, write into it and close it:"
      ],
      "metadata": {
        "id": "1euU8jxBzxfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"goncharov_obryv_lemmas.txt\", \"w\")\n",
        "f.write(''.join(lemmas))\n",
        "f.close()"
      ],
      "metadata": {
        "id": "1Z1SfuGtRi7T"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The saved text looks like this:"
      ],
      "metadata": {
        "id": "ELrycLbX1AQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(''.join(lemmas)[84:284])"
      ],
      "metadata": {
        "id": "uQ5FrcCG1DXZ",
        "outputId": "29e82737-c50a-4c77-90a3-ecf5494511b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "два господин сидеть в небрежно убирать квартира в петербург, на один из большой улица. один быть около тридцать пять, а другой около сорок пять год.\n",
            "\n",
            "первый быть борис павлович райский, второй -- иван\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1. Tokenizing with NLTK"
      ],
      "metadata": {
        "id": "WbJPsiHATKwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5H1LZG2TOZx",
        "outputId": "10ed4654-49fa-491d-b2f5-d47bfc78bbb0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = nltk.word_tokenize(novel)"
      ],
      "metadata": {
        "id": "vnCXzUWFTWXu"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens[100:110]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7kVt75BTatF",
        "outputId": "21dbdc77-e541-46a9-ac92-8f9444be3aff"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.', 'Иногда', 'же', 'смотрели', 'они', 'зрело', ',', 'устало', ',', 'скучно']"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Analysing tokens with pymorphy\n"
      ],
      "metadata": {
        "id": "Uthg10fJcmMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymorphy2 import MorphAnalyzer\n",
        "morph = MorphAnalyzer()"
      ],
      "metadata": {
        "id": "MxYK5lRMcloM"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def token_to_dict(token):\n",
        "  analysis = morph.parse(token)[0]\n",
        "  return {\"lemma\": analysis.normal_form, \"word\": analysis.word, \"pos\": analysis.tag.POS}\n",
        "\n",
        "tokens_analysis = list(map(token_to_dict, tokens))"
      ],
      "metadata": {
        "id": "7nmrp_w-c8Pc"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens_analysis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Byi6vRT_qWfg",
        "outputId": "1358dbcd-d009-4d92-80c4-7e2da35f1f48"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "306236"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_analysis = list(filter(lambda tkn: tkn[\"pos\"] != None, tokens_analysis))"
      ],
      "metadata": {
        "id": "R7BfE9qNqZm7"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens_analysis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70atrRnCqn0j",
        "outputId": "581d947e-fd5c-4289-f34b-237eb10c4100"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "226709"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_analysis[100:110]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okr_YVQLgu4f",
        "outputId": "e67f5558-fd3a-496d-fa59-db353a7812cb"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'lemma': 'этот', 'word': 'эти', 'pos': 'ADJF'},\n",
              " {'lemma': 'неизгладимый', 'word': 'неизгладимые', 'pos': 'ADJF'},\n",
              " {'lemma': 'знак', 'word': 'знаки', 'pos': 'NOUN'},\n",
              " {'lemma': 'время', 'word': 'времени', 'pos': 'NOUN'},\n",
              " {'lemma': 'и', 'word': 'и', 'pos': 'CONJ'},\n",
              " {'lemma': 'опыт', 'word': 'опыта', 'pos': 'NOUN'},\n",
              " {'lemma': 'гладкий', 'word': 'гладкие', 'pos': 'ADJF'},\n",
              " {'lemma': 'чёрный', 'word': 'чёрные', 'pos': 'ADJF'},\n",
              " {'lemma': 'волос', 'word': 'волосы', 'pos': 'NOUN'},\n",
              " {'lemma': 'падать', 'word': 'падали', 'pos': 'VERB'}]"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 4"
      ],
      "metadata": {
        "id": "XIFrxg8rmEKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parts_of_speech = set(map(lambda tkn: tkn[\"pos\"], tokens_analysis))\n",
        "\n",
        "for pos in parts_of_speech:\n",
        "  share = len(list(filter(lambda tkn: tkn[\"pos\"] == pos, tokens_analysis)))/len(tokens_analysis)\n",
        "  print(pos + \": \" + str(share))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdDajwcRsFSc",
        "outputId": "be44aced-db56-467e-e8fd-0b39f0b7b55e"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INTJ: 0.001323282269340873\n",
            "ADVB: 0.06901799222792214\n",
            "PRCL: 0.06582447101791283\n",
            "ADJS: 0.00862338945520469\n",
            "PRTF: 0.006550247233237322\n",
            "CONJ: 0.11151740777825318\n",
            "VERB: 0.15375657781561386\n",
            "PRTS: 0.0017511435364277554\n",
            "NPRO: 0.11709283707307606\n",
            "PREP: 0.1009311496235262\n",
            "NOUN: 0.22016770397293448\n",
            "PRED: 0.0064796721788724755\n",
            "INFN: 0.02794772152847924\n",
            "ADJF: 0.08848347440992638\n",
            "COMP: 0.003956613985329211\n",
            "GRND: 0.012090389000877777\n",
            "NUMR: 0.00448592689306556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nsJfH0Tgtjl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK\n",
        "\n",
        "\n",
        "1. Choose a novel or any other long text, e.g., from http://lib.ru/ and save it in the .txt format. Check that the encoding is UTF-8\n",
        "\n",
        "2. (2 points) Lemmatize the text using mystem (if you absolutely do not want to use mystem, you can use any other suitable tool we have discussed) and save the result into a .txt file\n",
        "\n",
        "3. (3 points)\n",
        "tokenize the text using nltk\n",
        "\n",
        "analyze the words using pymorphy\n",
        "\n",
        "save the results of the analysis in jsonlines (.jsonl): every line contains morphological analysis in a form of a dictionary {\"lemma\": \"конь\", \"word\": \"коня\", \"pos\": \"NOUN\"}\n",
        "4. (2 points) Answer the following questions:\n",
        "\n",
        "What percentage constitutes each pos? (E.g., for the verb, the number of verbs divided by the total number of words)\n",
        "\n",
        "Print out top-20 verbs and adverbs\n",
        "\n",
        "you can keep the stop words or you can get rid of them\n",
        "5. (1 point) Find top-25 bigrams and trigrams for your text (use nltk.bigrams), use only lemmas, get rid of the punctuation. Comment shortly on the results.\n",
        "\n",
        "6. (2 points) Take 3-8 sentences from the original text and substitute some morphological information, for example, change the tense of the verbs, the number of the nouns, e.g, the original Слон подарил мартышке цветы should become Слоны подарят мартышкам цветок."
      ],
      "metadata": {
        "id": "M4iDQZuZT8AF"
      }
    }
  ]
}