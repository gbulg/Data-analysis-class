{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgDi8wLCr+4XZ/SYdiNWTA"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 1\n",
        "\n",
        "First, make sure all needed packages are installed:\n"
      ],
      "metadata": {
        "id": "RQX0Czcu6gLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pymystem3 nltk pymorphy2"
      ],
      "metadata": {
        "id": "Yp6FqyZN6lkz",
        "outputId": "fe00649f-34d4-4eef-eed2-0493783e45ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pymystem3 in /usr/local/lib/python3.8/dist-packages (0.2.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.8/dist-packages (0.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from pymystem3) (2.25.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.8/dist-packages (from pymorphy2) (2.4.417127.4579844)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.8/dist-packages (from pymorphy2) (0.6.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->pymystem3) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->pymystem3) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->pymystem3) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->pymystem3) (4.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Read the novel text from txt file\n",
        "\n",
        "Open the txt file, read from it and then close it."
      ],
      "metadata": {
        "id": "JUQCP9P6sf-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"./goncharov_obryv.txt\", \"r\")\n",
        "novel = f.read()\n",
        "f.close()"
      ],
      "metadata": {
        "id": "kwwp_pb-tcbi"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print first 500 characters to make sure everything is fine:"
      ],
      "metadata": {
        "id": "4tveqYz6wlFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(novel[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2RuviDLvfTI",
        "outputId": "28cb5d18-9f51-403c-9da4-d95d774ebbb1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Иван Александрович Гончаров\n",
            "\n",
            "Обрыв\n",
            "\n",
            "Роман в пяти частях.\n",
            "\n",
            "\n",
            "\n",
            "ЧАСТЬ ПЕРВАЯ\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "I\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Два господина сидели в небрежно убранной квартире в Петербурге, на одной из больших улиц. Одному было около тридцати пяти, а другому около сорока пяти лет.\n",
            "\n",
            "Первый был Борис Павлович Райский, второй -- Иван Иванович Аянов.\n",
            "\n",
            "У Бориса Павловича была живая, чрезвычайно подвижная физиономия. С первого взгляда он казался моложе своих лет: большой белый лоб блистал свежестью, глаза менялись, то загорались мыслию, чувс\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 2. Lemmatize text using Mystem and save it\n",
        "\n",
        "First, import Mystem and create an instance of Mystem class:"
      ],
      "metadata": {
        "id": "6vkOg3fDDOIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymystem3 import Mystem\n",
        "\n",
        "m = Mystem()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXstzjieDZD5",
        "outputId": "fdbae98f-16f3-41f6-ac84-d8031abf09ae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing mystem to /root/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatize the text, and print a short slice of the obtained lemmas list:"
      ],
      "metadata": {
        "id": "LZMwpZ_lyXyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmas = m.lemmatize(novel)"
      ],
      "metadata": {
        "id": "SI0P-iutG4Ie"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmas[50:60]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIR6xO5GzTUS",
        "outputId": "d63f06ee-f729-4cec-a2d2-8785ecb10882"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['квартира', ' ', 'в', ' ', 'петербург', ', ', 'на', ' ', 'один', ' ']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to save this lemmatization into the new txt file. I'm not sure how exactly it should be formatted, so I will just join these normal forms of words into the new text and save it like that.\n",
        "\n",
        "Open the file for writing, write into it and close it:"
      ],
      "metadata": {
        "id": "1euU8jxBzxfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"lemmatized_text.txt\", \"w\")\n",
        "f.write(''.join(lemmas))\n",
        "f.close()"
      ],
      "metadata": {
        "id": "1Z1SfuGtRi7T"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The saved text looks like this:"
      ],
      "metadata": {
        "id": "ELrycLbX1AQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(''.join(lemmas)[84:284])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQ5FrcCG1DXZ",
        "outputId": "29f42416-616d-4334-d269-0ae1bfc11e36"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "два господин сидеть в небрежно убирать квартира в петербург, на один из большой улица. один быть около тридцать пять, а другой около сорок пять год.\n",
            "\n",
            "первый быть борис павлович райский, второй -- иван\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 3 Tokenizing the text with NLTK and use pymorphy to analyze words\n",
        "\n",
        "First, import NLTK.\n"
      ],
      "metadata": {
        "id": "WbJPsiHATKwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5H1LZG2TOZx",
        "outputId": "7c7373fa-91fe-401a-c77a-09e4f442a31f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize the text and print a short slice of the obtained token list:"
      ],
      "metadata": {
        "id": "UzgIlgjM21Je"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = nltk.word_tokenize(novel)"
      ],
      "metadata": {
        "id": "vnCXzUWFTWXu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens[100:110]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7kVt75BTatF",
        "outputId": "a5e94dc9-45dc-4a45-caeb-5ee275344716"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.', 'Иногда', 'же', 'смотрели', 'они', 'зрело', ',', 'устало', ',', 'скучно']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's analyze these tokens with pymorphy. Import the library and create an instance of it:"
      ],
      "metadata": {
        "id": "2arDv2Za3N7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pymorphy2 as mph\n",
        "\n",
        "morph = mph.MorphAnalyzer()"
      ],
      "metadata": {
        "id": "MxYK5lRMcloM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I define a function `token_to_dict` that analyzes one token and returns a dictionary for it in desired format, and then create a list of such dictionaries by applying this function to each token. \n",
        "\n"
      ],
      "metadata": {
        "id": "C2HlXuvk3dyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def token_to_dict(token):\n",
        "  analysis = morph.parse(token)[0] # take the analysis with the highest score\n",
        "  return {\"lemma\": analysis.normal_form, \"word\": analysis.word, \"pos\": analysis.tag.POS}"
      ],
      "metadata": {
        "id": "7nmrp_w-c8Pc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_analysis = list(map(token_to_dict, tokens))"
      ],
      "metadata": {
        "id": "HtvT_yQM7l78"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now is good time to get rid of all punctuation, as all such tokens have their POS value equal to `None` and can easily be filtered out. I also count the number of tokens before and after the filtering."
      ],
      "metadata": {
        "id": "CMBa3oJb6dlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens_analysis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Byi6vRT_qWfg",
        "outputId": "2fc47d2f-8570-443b-cec2-fd67e22f39a7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "306236"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_analysis = list(filter(lambda tkn: tkn[\"pos\"] != None, tokens_analysis))"
      ],
      "metadata": {
        "id": "R7BfE9qNqZm7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens_analysis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70atrRnCqn0j",
        "outputId": "04391204-03ca-4de3-8985-3eb4e3ab53d1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "226709"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that approximately 80,000 tokens were filtered out. Here is a short slice of the obtaned array of dicts:"
      ],
      "metadata": {
        "id": "f15e1Zlq7WB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_analysis[100:110]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okr_YVQLgu4f",
        "outputId": "faee3931-2f1c-4e36-8023-9c870b8bd9e1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'lemma': 'этот', 'word': 'эти', 'pos': 'ADJF'},\n",
              " {'lemma': 'неизгладимый', 'word': 'неизгладимые', 'pos': 'ADJF'},\n",
              " {'lemma': 'знак', 'word': 'знаки', 'pos': 'NOUN'},\n",
              " {'lemma': 'время', 'word': 'времени', 'pos': 'NOUN'},\n",
              " {'lemma': 'и', 'word': 'и', 'pos': 'CONJ'},\n",
              " {'lemma': 'опыт', 'word': 'опыта', 'pos': 'NOUN'},\n",
              " {'lemma': 'гладкий', 'word': 'гладкие', 'pos': 'ADJF'},\n",
              " {'lemma': 'чёрный', 'word': 'чёрные', 'pos': 'ADJF'},\n",
              " {'lemma': 'волос', 'word': 'волосы', 'pos': 'NOUN'},\n",
              " {'lemma': 'падать', 'word': 'падали', 'pos': 'VERB'}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's create a `.jsonl` file and save this information there. I import `json` library and use `json.dumps` to turn dicts into JSON strings."
      ],
      "metadata": {
        "id": "ISOxeJdx8FpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "57ictc849VSD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"analyzed_tokens.jsonl\", \"w\", encoding=\"utf-8\")\n",
        "f.write('\\n'.join(json.dumps(tkn, ensure_ascii=False) for tkn in tokens_analysis))\n",
        "f.close()"
      ],
      "metadata": {
        "id": "S71oxAct8GUx"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 4.1. Calculating the shares of each part of speech\n",
        "\n",
        "To do so, I first extact a list of all unique values of POS by using `set`. Then, for each part of speech, I calculate its share by filtering only tokens of this POS, counting them, and dividing their amount by the overall token amount."
      ],
      "metadata": {
        "id": "XIFrxg8rmEKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parts_of_speech = set(tkn[\"pos\"] for tkn in tokens_analysis)\n",
        "\n",
        "for pos in parts_of_speech:\n",
        "  share = len(list(filter(lambda tkn: tkn[\"pos\"] == pos, tokens_analysis))) / len(tokens_analysis) * 100\n",
        "  print(pos + \":\\t\" + f\"{share:.2f}\" + \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdDajwcRsFSc",
        "outputId": "ae2dcaed-7b12-4023-8a12-869709b8deb9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ADVB:\t6.90%\n",
            "NPRO:\t11.71%\n",
            "VERB:\t15.38%\n",
            "CONJ:\t11.15%\n",
            "INFN:\t2.79%\n",
            "PRCL:\t6.58%\n",
            "PRTS:\t0.18%\n",
            "ADJF:\t8.85%\n",
            "COMP:\t0.40%\n",
            "NOUN:\t22.02%\n",
            "INTJ:\t0.13%\n",
            "PRED:\t0.65%\n",
            "PRTF:\t0.66%\n",
            "NUMR:\t0.45%\n",
            "PREP:\t10.09%\n",
            "GRND:\t1.21%\n",
            "ADJS:\t0.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the most frequent categories are Nouns (22%), Verbs (15%), Pronouns (11%), Conjunctives (11%) and Prepositions (10%)."
      ],
      "metadata": {
        "id": "wk78egpLD1AN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 4.2. Most frequent Verbs and Adverbs\n",
        "\n",
        "To obtain the top-20 most frequent Verbs and Adverbs, I will use the `Counter` class."
      ],
      "metadata": {
        "id": "CACsEIjLE9ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "6jOEJbUfH62X"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, I construct the `verbs` list, which contains all verb lemmas (with repititions).\n"
      ],
      "metadata": {
        "id": "AiLujA7YPy_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "verbs = [tkn[\"lemma\"] for tkn in tokens_analysis if tkn[\"pos\"] == \"VERB\"]"
      ],
      "metadata": {
        "id": "uRWgOYQ3Pvo5"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `Counter` class allows to obtain two lists: `Counter(verbs).keys()` is a list of unique verb lemmas, `Counter(verbs).values()` is a list of the same size that for each unique lemma contains number of its occurencies in the `verbs` list. \n",
        "\n",
        "Then, I sort `Counter(verbs).keys()` in the descending order of corresponding values in `Counter(verbs).values()` by using `zip`. I obtain `sorted_verbs` -- a list of tuples of lemmas and number of their occurencies, sorted such that the most frequent ones are at the top."
      ],
      "metadata": {
        "id": "E8dZRxpnKqcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_verbs = sorted(zip(Counter(verbs).values(), Counter(verbs).keys()), reverse=True)"
      ],
      "metadata": {
        "id": "bdQjhxlAFPpS"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the top-20 verbs:"
      ],
      "metadata": {
        "id": "i-bTTqeyN2sT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for count, lemma in sorted_verbs[:20]:\n",
        "  print(lemma + \"\\t\" + str(count) + \" occurencies\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhX1BdJyMwRk",
        "outputId": "0bf06b77-18a9-497b-c4e2-6e56605f9c3d"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "быть\t1938 occurencies\n",
            "сказать\t1412 occurencies\n",
            "говорить\t866 occurencies\n",
            "хотеть\t614 occurencies\n",
            "знать\t606 occurencies\n",
            "мочь\t557 occurencies\n",
            "спросить\t427 occurencies\n",
            "любить\t415 occurencies\n",
            "стать\t388 occurencies\n",
            "видеть\t386 occurencies\n",
            "думать\t354 occurencies\n",
            "пойти\t321 occurencies\n",
            "дать\t275 occurencies\n",
            "смотреть\t258 occurencies\n",
            "сделать\t242 occurencies\n",
            "идти\t218 occurencies\n",
            "заметить\t217 occurencies\n",
            "казаться\t205 occurencies\n",
            "взять\t190 occurencies\n",
            "делать\t182 occurencies\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the same for the adverbs."
      ],
      "metadata": {
        "id": "NNRpjUcBKThy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adverbs = [tkn[\"lemma\"] for tkn in tokens_analysis if tkn[\"pos\"] == \"ADVB\"]\n",
        "sorted_adverbs = sorted(zip(Counter(adverbs).values(), Counter(adverbs).keys()), reverse=True)"
      ],
      "metadata": {
        "id": "OhNjidSHIA4E"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for count, lemma in sorted_adverbs[:20]:\n",
        "  print(lemma + \"\\t\" + str(count) + \" occurencies\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsiJZto8JvSa",
        "outputId": "594b3150-fbdf-418e-b9f9-5b3c1cfb0c69"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "только\t775 occurencies\n",
            "ещё\t627 occurencies\n",
            "потом\t534 occurencies\n",
            "опять\t509 occurencies\n",
            "теперь\t440 occurencies\n",
            "вдруг\t386 occurencies\n",
            "там\t379 occurencies\n",
            "ничего\t375 occurencies\n",
            "где\t317 occurencies\n",
            "почти\t252 occurencies\n",
            "тут\t237 occurencies\n",
            "зачем\t224 occurencies\n",
            "уже\t212 occurencies\n",
            "уж\t196 occurencies\n",
            "здесь\t188 occurencies\n",
            "никогда\t181 occurencies\n",
            "вон\t176 occurencies\n",
            "тогда\t170 occurencies\n",
            "иногда\t166 occurencies\n",
            "тихо\t159 occurencies\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 5. Bigrams and Trigrams\n",
        "\n",
        "Since we already got rid of punctuation in `tokens_analysis`, we can extract the `lemma` column from there to get the list of lemmas that is cleared from punctuation."
      ],
      "metadata": {
        "id": "vvsiAl5mVdbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmas = [tkn[\"lemma\"] for tkn in tokens_analysis]\n",
        "lemmas[100:110]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zplzGNKLVhta",
        "outputId": "784932bb-7a09-49f7-8978-456bcfbc98e6"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['этот',\n",
              " 'неизгладимый',\n",
              " 'знак',\n",
              " 'время',\n",
              " 'и',\n",
              " 'опыт',\n",
              " 'гладкий',\n",
              " 'чёрный',\n",
              " 'волос',\n",
              " 'падать']"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the list of bigrams using NLTK:"
      ],
      "metadata": {
        "id": "n9txt9cmWPQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bigrams = list(nltk.bigrams(lemmas))"
      ],
      "metadata": {
        "id": "SnpBKyMQWPyQ"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sort them exactly in the same way, as in top-20 verbs and adverbs:"
      ],
      "metadata": {
        "id": "o0YdXyccWoie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_bigrams = sorted(zip(Counter(bigrams).values(), Counter(bigrams).keys()), reverse=True)"
      ],
      "metadata": {
        "id": "2tFYDHr1WvzR"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for count, bigram in sorted_bigrams[:25]:\n",
        "  print(\"{0:20} \\t {1} occurencies\".format(\" \".join(bigram), str(count)))\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zu4zrSBDW0L-",
        "outputId": "f5d6e18a-3bda-48d4-9d5c-7ba3bacde69e"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "я не                 \t 415 occurencies\n",
            "и не                 \t 413 occurencies\n",
            "татьяна маркович     \t 377 occurencies\n",
            "сказать она          \t 326 occurencies\n",
            "она и                \t 306 occurencies\n",
            "она не               \t 305 occurencies\n",
            "у он                 \t 295 occurencies\n",
            "сказать он           \t 278 occurencies\n",
            "он не                \t 272 occurencies\n",
            "не знать             \t 272 occurencies\n",
            "на он                \t 254 occurencies\n",
            "что я                \t 253 occurencies\n",
            "не быть              \t 253 occurencies\n",
            "у она                \t 245 occurencies\n",
            "он и                 \t 243 occurencies\n",
            "не мочь              \t 239 occurencies\n",
            "как будто            \t 225 occurencies\n",
            "что он               \t 222 occurencies\n",
            "он в                 \t 220 occurencies\n",
            "на она               \t 219 occurencies\n",
            "что вы               \t 207 occurencies\n",
            "что она              \t 204 occurencies\n",
            "глядеть на           \t 201 occurencies\n",
            "и в                  \t 186 occurencies\n",
            "у я                  \t 185 occurencies\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The same for trigrams."
      ],
      "metadata": {
        "id": "KhXZF_mnZP_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trigrams = list(nltk.trigrams(lemmas))\n",
        "sorted_trigrams = sorted(zip(Counter(trigrams).values(), Counter(trigrams).keys()), reverse=True)\n",
        "\n",
        "for count, trigram in sorted_trigrams[:25]:\n",
        "  print(\"{0:20} \\t {1} occurencies\".format(\" \".join(trigram), str(count)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cp7YsFcHXGgt",
        "outputId": "c3239fe3-119b-49d5-9822-0430195a2451"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "глядеть на он        \t 63 occurencies\n",
            "в сам дело           \t 58 occurencies\n",
            "не знать что         \t 49 occurencies\n",
            "глядеть на она       \t 47 occurencies\n",
            "я не хотеть          \t 32 occurencies\n",
            "я не знать           \t 31 occurencies\n",
            "что же вы            \t 31 occurencies\n",
            "татьяна маркович и   \t 31 occurencies\n",
            "на другой день       \t 31 occurencies\n",
            "я ничего не          \t 29 occurencies\n",
            "она за рука          \t 29 occurencies\n",
            "если б я             \t 29 occurencies\n",
            "у он в               \t 27 occurencies\n",
            "сказать она и        \t 27 occurencies\n",
            "что она не           \t 26 occurencies\n",
            "и не мочь            \t 26 occurencies\n",
            "сказать татьяна маркович \t 24 occurencies\n",
            "не глядеть на        \t 24 occurencies\n",
            "взглянуть на он      \t 24 occurencies\n",
            "в этот минута        \t 24 occurencies\n",
            "поглядеть на он      \t 23 occurencies\n",
            "что я не             \t 22 occurencies\n",
            "она не быть          \t 22 occurencies\n",
            "она и не             \t 22 occurencies\n",
            "он глядеть на        \t 22 occurencies\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some commentary"
      ],
      "metadata": {
        "id": "soTrPyg1bAA0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 6. Altering morphological parameters\n",
        "\n",
        "Take 3-8 sentences from the original text and substitute some morphological information, for example, change the tense of the verbs, the number of the nouns, e.g, the original Слон подарил мартышке цветы should become Слоны подарят мартышкам цветок."
      ],
      "metadata": {
        "id": "2VzSvm77ZyWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = novel[1321:1392]\n",
        "print(sentence1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCHtmd4HaakJ",
        "outputId": "d970d016-467d-41a9-b52e-1fcb4dc8dd05"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Райский одет был в домашнее серенькое пальто, сидел с ногами на диване.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence2 = novel[7326:7348]\n",
        "print(sentence2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXDnwuDqa6rR",
        "outputId": "e7b5a089-33d5-4954-ba8a-c07645f51cae"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Так грозил ему доктор.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence3 = novel[10082:10119]\n",
        "print(sentence3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGZFajfIcv6E",
        "outputId": "59ab9a8f-991b-4f2f-ac28-6ad4615f4807"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "А вот с женщиной биться зиму и весну!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence4 = novel[11000:21000]\n",
        "sentence4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "WV8d6f1MdUoq",
        "outputId": "edbd7753-1468-4248-eec0-579edf54b7e5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'чти всегда, а я всегда проигрываю... Что же тут дурного?\\n\\n-- Да. Софья Николаевна красавица, да еще богатая невеста: женись, и конец всему.\\n\\n-- Да -- и конец всему, и начало скуке! -- задумчиво повторил Райский. -- А я не хочу конца! Успокойся, за меня бы ее и не отдали!\\n\\n-- Тогда, по-моему, и ходить незачем. Ты просто -- Дон-Жуан!\\n\\n-- Да, Дон-Жуан, пустой человек: так, что ли, по-вашему?\\n\\n-- А как же: что ж они, по-твоему? -- Ну, так и Байрон, и Гете, и куча живописцев, скульпторов -- все были пустые люди... -- Да ты -- Байрон или Гете, что ли?.. Райский с досадой отвернулся от него.\\n\\n-- Донжуанизм -- то же в людском роде, что донкихотство: еще глубже; эта потребность еще прирожденнее... -- сказал он. -- Коли потребность -- так женись... я тебе говорю... -- Ах! -- почти с отчаянием произнес Райский. -- Ведь жениться можно один, два, три раза: ужели я не могу наслаждаться красотой так, как бы наслаждался красотой в статуе? Дон-Жуан наслаждался прежде всего эстетически этой потребностью, но грубо: сын своего века, воспитания, нравов, он увлекался за пределы этого поклонения -- вот и все. Да что толковать с тобой!\\n\\n-- Коли не жениться, так незачем и ходить, -- апатично повторил Аянов.\\n\\n-- А знаешь -- ты отчасти прав. Прежде всего скажу, что мои увлечения всегда искренни и не умышленны, -- это не волокитство -- знай однажды навсегда. И когда мой идол хоть одной чертой подходит к идеалу, который фантазия сейчас создает мне из него, -- у меня само собою доделается остальное, и тогда возникает идеал счастья, семейного...\\n\\n-- Вот видишь; ну так и женись...- заметил Аянов. -- Погоди, погоди: никогда ни один идеал не доживал до срока свадьбы: бледнел, падал, и я уходил охлажденный... Что фантазия создает, то анализ разрушает, как карточный домик. Или сам идеал, не дождавшись охлаждения, уходит от меня...\\n\\n-- А все-таки каждый день сидеть с женщиной и болтать!..- упрямо твердил Аянов, покачивая головой.- Ну о чем, например, ты будешь говорить хоть сегодня? Чего ты хочешь от нее, если ее за тебя не выдадут?\\n\\n-- И я тебя спрошу: чего ты хочешь от ее теток? Какие карты к тебе придут? Выиграешь ты или проиграешь? Разве ты ходишь с тем туда, чтоб выиграть все шестьдесят тысяч дохода? Ходишь поиграть -- и выиграть что-нибудь...\\n\\n-- У меня никаких расчетов нет: я делаю это от... от ... для удовольствия.\\n\\n-- От... от скуки -- видишь, и я для удовольствия -- и тоже без расчетов. А как я наслаждаюсь красотой, ты и твой Иван Петрович этого не поймете, не во гнев тебе и ему -- вот и все. Ведь есть же одни, которые молятся страстно, а другие не знают этой потребности, и...\\n\\n-- Страстно! Страсти мешают жить. Труд -- вот одно лекарство от пустоты: дело, -- сказал Аянов внушительно.\\n\\nРайский остановился, остановил Аянова, ядовито улыбнулся и спросил: \"Какое дело, скажи, пожалуйста: это любопытно!\"\\n\\n-- Как какое? Служи.\\n\\n-- Разве это дело? Укажи ты мне в службе, за немногими исключениями, дело, без которого бы нельзя было обойтись?\\n\\nАянов засвистал от удивления.\\n\\n-- Вот тебе раз! -- сказал он и поглядел около себя. -- Да вот! -- Он указал на полицейского чиновника, который упорно глядел в одну сторону.\\n\\n-- А спроси его, -- сказал Райский, -- зачем он тут стоит и кого так пристально высматривает и выжидает? Генерала! А нас с тобой не видит, так что любой прохожий может вытащить у нас платок из кармана. Ужели ты считал делом твои бумаги? Не будем распространяться об этом, а скажу тебе, что я, право, больше делаю, когда мажу свои картины, бренчу на рояле и даже когда поклоняюсь красоте...\\n\\n-- И что особенного, кроме красоты, нашел ты в своей кузине?\\n\\n-- Кроме красоты! Да это все! Впрочем, я мало знаю ее: это-то, вместе с красотой. и влечет меня к ней...\\n\\n-- Как, каждый день вместе и мало знаешь?..\\n\\n-- Мало. Не знаю, что у нее кроется под этим спокойствием, не знаю ее прошлого и не угадываю ее будущего. Женщина она или кукла, живет или подделывается под жизнь? И это мучит меня... Вон, смотри, -- продолжал Райский, -- видишь эту женщину?\\n\\n-- Ту толстую, что лезет с узлом на извозчика?\\n\\n-- Да, и вот эту, что глядит из окна кареты? И вон ту, что заворачивает из-за угла навстречу нам?\\n\\n-- Ну, так что же?\\n\\n-- Ты на их лицах мельком прочтешь какую-нибудь заботу, или тоску, или радость, или мысль, признак воли: ну, словом, -- движение, жизнь. Немного нужно, чтоб подобрать ключ и сказать, что тут семья и дети, значит, было прошлое, а там глядит страсть или живой след симпатии, -- значит, есть настоящее, а здесь на молодом лице играют надежды, просятся наружу желания и пророчат беспокойное будущее...\\n\\n-- Ну?\\n\\n-- Ну, везде что-то живое, подвижное, требующее жизни и отзывающееся на нее... А там ничего этого нет, ничего, хоть шаром покати! Даже нет апатии, скуки, чтоб можно было сказать: была жизнь и убита -- ничего! Сияет и блестит, ничего не просит и ничего не отдает! И я ничего не знаю! А ты удивляешься, что я бьюсь?\\n\\n-- Давно бы сказал мне это, и я удивляться перестал бы, потому что я сам такой, -- сказал Аянов, вдруг останавливаясь.- Ходи ко мне, вместо нее...\\n\\n-- Ты?\\n\\n-- Да -- я!\\n\\n-- Что же ты, красотой блистаешь?..\\n\\n-- Блистаю спокойствием и наслаждаюсь этим; и она тоже... Что тебе за дело?..\\n\\n-- До тебя -- никакого, а она -- красота, красота!\\n\\n-- Женись, а не хочешь или нельзя, так оставь, займись делом...\\n\\n-- Ты прежде заведи дело, в которое мог бы броситься живой ум, гнушающийся мертвечины, и страстная душа, и укажи, как положить силы во что-нибудь, что стоит борьбы, -- а с своими картами, визитами, раутами и службой -- убирайся к черту!\\n\\n-- У тебя беспокойная натура, -- сказал Аянов, -- не было строгой руки и тяжелой школы -- вот ты и куролесишь... Помнишь, ты рассказывал, когда твоя Наташа была жива... Райский вдруг остановился и, с грустью на лице, схватил своего спутника за руку. -- Наташа! -- повторил он тихо,- это единственный, тяжелый камень у меня на душе -- не мешай память о ней в эти мои впечатления и мимолетные увлечения... Он вздохнул, и они молча дошли до Владимирской церкви, свернули в переулок и вошли в подъезд барского дома.\\n\\n\\n\\n\\n\\nII\\n\\n\\n\\n\\n\\nРайский с год только перед этим познакомился с Софьей Николаевной Беловодовой, вдовой на двадцать пятом году, после недолгого замужества с Беловодовым, служившим по дипломатической части. Она была из старинного богатого дом Пахотиных. Матери она лишилась еще до замужества, и батюшка ее, состоявший в полном распоряжении супруги, почувствовав себя на свободе, вдруг спохватился, что молодость его рано захвачена была женитьбой и что он не успел пожить и пожуировать. Он повел было жизнь холостяка, пересиливал годы и природу, но не пересилил и только смотрел, как ели и пили другие, а у него желудок не варил. Но он уже успел нанести смертельный удар своему состоянию. У него, взамен наслаждений, которыми он пользоваться не мог, явилось старческое тщеславие иметь вид шалуна, и он стал вознаграждать себя за верность в супружестве сумасбродными связями, на которые быстро ушли все наличные деньги, брильянты жены, наконец и большая часть приданого дочери. На недвижимое имение, и без того заложенное им еще до женитьбы, наросли значительные долги.\\n\\nКогда источники иссякли, он изредка, в год раз, иногда два, сделает дорогую шалость, купит брильянты какой-нибудь Armance, экипаж, сервиз, ездит к ней недели три, провожает в театр, делает ей ужины, сзывает молодежь, а потом опять смолкает до следующих денег.\\n\\nНиколай Васильевич Пахотин был очень красивый сановитый старик, с мягкими, почтенными сединами. По виду его примешь за какого-нибудь Пальмерстона.\\n\\nОсобенно красив он был, когда с гордостью вел под руку Софью Николаевну куда-нибудь на бал, на общественное гулянье. Не знавшие его почтительно сторонились, а знакомые, завидя шалуна, начинали уже улыбаться и потом фамильярно и шутливо трясти его за руку, звали устроить веселый обед, рассказывали на ухо приятную историю...\\n\\nСтарик шутил, рассказывал сам направо и налево анекдоты, говорил каламбуры, особенно любил с сверстниками жить воспоминаниями минувшей молодости и своего времени. Они с восторгом припоминали, как граф Борис или Денис проигрывал кучи золота; терзались тем, что сами тратили так мало, жили так мизерно; поучали внимательную молодежь великому искусству жить.\\n\\nНо особенно любил Пахотин уноситься воспоминаниями в Париж, когда в четырнадцатом году русские явились великодушными победителями, перещеголявшими любезностью тогдашних французов, уже попорченных в этом отношении революцией, и превосходившими безумным мотовством широкую щедрость англичан.\\n\\nСтарик шутя проживал жизнь, всегда смеялся, рассказывал только веселое, даже на драму в театре смотрел с улыбкой, любуясь ножкой или лорнируя la gorge {Грудь -- фр.} актрисы.\\n\\nКогда же наставало не веселое событие, не обед, не соблазнительная закулисная драма, а затрогивались нервы жизни, слышался в ней громовой раскат, когда около него возникал важный вопрос, требовавший мысли или воли, старик тупо недоумевал, впадал в беспокойное молчание и только учащенно жевал губами. У него был живой, игривый ум, наблюдательность и некогда смелые порывы в характере. Но шестнадцати лет он поступил в гвардию, выучась отлично говорить, писать и петь по-французски и почти на зная русской грамоты. Ему дали отличную квартиру, лошадей, экипаж и тысяч двадцать дохода.\\n\\nНикто лучше его не был одет, и теперь еще, в старости, он дает законы вкуса портному; все на нем сидит отлично, ходит он бодро, благородно, говорит с уверенностью и никогда не выходит из себя. Судит обо всем часто наперекор логике, но владеет софизмом с необыкновенною ловкостью.\\n\\nС ним можно не согласиться, но сбить его трудно. Свет, опыт, вся жизнь его не дали ему никакого содержания, и оттого он боится серьезного, как огня. Но тот же опыт, жизнь всегда в куче людей, множество встреч и способность знакомиться со всеми образовывали ему какой-то очень приятный, мелкий умок, и не знающий его с первого раза даже положится на его совет, суждение и потом уже, жестоко обманувшись, разглядит, что это за человек.\\n\\nОн не успел еще окунуться в омут опасной, при праздности'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stokens_parse = [morph.parse(tkn)[0] for tkn in nltk.word_tokenize(sentence3)]\n",
        "stokens_parse"
      ],
      "metadata": {
        "id": "1LIZWtaMl1ii",
        "outputId": "517c7407-5e59-4288-eafd-9a0f83928cd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parse(word='а', tag=OpencorporaTag('CONJ'), normal_form='а', score=0.997155, methods_stack=((DictionaryAnalyzer(), 'а', 20, 0),)),\n",
              " Parse(word='вот', tag=OpencorporaTag('PRCL'), normal_form='вот', score=1.0, methods_stack=((DictionaryAnalyzer(), 'вот', 22, 0),)),\n",
              " Parse(word='с', tag=OpencorporaTag('PREP'), normal_form='с', score=0.997625, methods_stack=((DictionaryAnalyzer(), 'с', 393, 0),)),\n",
              " Parse(word='женщиной', tag=OpencorporaTag('NOUN,anim,femn sing,ablt'), normal_form='женщина', score=1.0, methods_stack=((DictionaryAnalyzer(), 'женщиной', 53, 4),)),\n",
              " Parse(word='биться', tag=OpencorporaTag('INFN,impf,intr'), normal_form='биться', score=1.0, methods_stack=((DictionaryAnalyzer(), 'биться', 466, 0),)),\n",
              " Parse(word='зиму', tag=OpencorporaTag('NOUN,inan,femn sing,accs'), normal_form='зима', score=1.0, methods_stack=((DictionaryAnalyzer(), 'зиму', 55, 3),)),\n",
              " Parse(word='и', tag=OpencorporaTag('CONJ'), normal_form='и', score=0.998263, methods_stack=((DictionaryAnalyzer(), 'и', 20, 0),)),\n",
              " Parse(word='весну', tag=OpencorporaTag('NOUN,inan,femn sing,accs'), normal_form='весна', score=1.0, methods_stack=((DictionaryAnalyzer(), 'весну', 488, 3),)),\n",
              " Parse(word='!', tag=OpencorporaTag('PNCT'), normal_form='!', score=1.0, methods_stack=((PunctuationAnalyzer(score=0.9), '!'),))]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def alter_morphology(sentence, *rules):\n",
        "  tokens = nltk.word_tokenize(sentence)\n",
        "  tokens_parse = [morph.parse(tkn)[0] for tkn in tokens]\n",
        "\n",
        "  result = \"\"\n",
        "  for tkn, orig_tkn in zip(tokens_parse, tokens):\n",
        "    for rule in rules:\n",
        "      tkn = rule(tkn)\n",
        "    if result != \"\" and not mph.shapes.is_punctuation(tkn.word): result += \" \"\n",
        "    result += mph.shapes.restore_capitalization(tkn.word, orig_tkn)\n",
        "  return result"
      ],
      "metadata": {
        "id": "skIMLGXMfVdT"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pluralize(tkn):\n",
        "  if 'sing' in tkn.tag and tkn.inflect({'plur'}) != None:\n",
        "    return tkn.inflect({'plur'})\n",
        "  return tkn"
      ],
      "metadata": {
        "id": "cxOIV6nmsyLO"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pastize(tkn):\n",
        "  if tkn.inflect({'past'}) != None:\n",
        "    return tkn.inflect({'past'})\n",
        "  return tkn"
      ],
      "metadata": {
        "id": "d1roal9UupvM"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence = sentence3\n",
        "print(test_sentence + \"\\n\" + alter_morphology(test_sentence, pluralize, pastize))"
      ],
      "metadata": {
        "id": "Mcrvnl5Zfl7b",
        "outputId": "43893735-49b4-40ed-effa-7c482e8207f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "А вот с женщиной биться зиму и весну!\n",
            "А вот с женщинами бившись зимы и вёсны!\n"
          ]
        }
      ]
    }
  ]
}